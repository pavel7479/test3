{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Нужно собрать google colab так, чтобы там можно было визуально работать не разработчику, в котором будет реализована следующая логика:\n",
        "\n",
        "Приходит запрос пользователя, Определяется вопрос позитивный или негативный. Если позитивный, то GPT отвечает как Бетмен. Если негативный, то как Джокер.\n",
        "\n",
        "Провести 10 тестов (отобразить результаты в колбае ниже). И ссылку на github"
      ],
      "metadata": {
        "id": "Xb2tM0XR9jZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка библиотек\n",
        "!pip install openai transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLtgKEBQA4_h",
        "outputId": "033eacb3-0005-434c-be3f-a7e14d0ea950"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.40.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Downloading openai-1.40.0-py3-none-any.whl (360 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.4/360.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Установка токена Hugging Face\n",
        "hf_token = \"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\"\n",
        "\n",
        "# Загрузка модели для анализа настроений\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\", token=hf_token)\n",
        "\n",
        "# Загрузка токенизатора и модели для генерации текста\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\", use_auth_token=hf_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\", use_auth_token=hf_token)\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    result = sentiment_analyzer(text)\n",
        "    sentiment = result[0]['label']\n",
        "    return sentiment\n",
        "\n",
        "def generate_text_with_context(prompt, context, style, max_length=150):\n",
        "    # Объединение контекста и запроса\n",
        "    full_prompt = f\"{context}\\n\\n{prompt}\"\n",
        "\n",
        "    # Выбор стиля для генерации текста\n",
        "    if style == \"batman\":\n",
        "        full_prompt = f\"В стиле Бэтмана: {full_prompt}\"\n",
        "    elif style == \"joker\":\n",
        "        full_prompt = f\"В стиле Джокера: {full_prompt}\"\n",
        "\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    attention_mask = inputs.get('attention_mask')\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length + len(inputs[\"input_ids\"][0]),  # Убедитесь, что ответ не выходит за пределы\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        "\n",
        "    # Декодирование ответа\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Обрезка текста до основного ответа (поиск конца контекста и начало ответа)\n",
        "    prompt_start_index = response.find(prompt)\n",
        "    if prompt_start_index != -1:\n",
        "        response = response[prompt_start_index + len(prompt):]\n",
        "\n",
        "    response_first_line = response.split('\\n')[0].strip()\n",
        "\n",
        "    return response_first_line\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        user_input = input(\"Введите ваш вопрос (или 'выход' для завершения): \")\n",
        "        if user_input.lower() == 'выход':\n",
        "            break\n",
        "\n",
        "        sentiment = analyze_sentiment(user_input)\n",
        "        print(f\"Sentiment: {sentiment}\")\n",
        "\n",
        "        if sentiment == \"NEGATIVE\":\n",
        "            style = \"joker\"\n",
        "            context = 'Мы разговариваем резко и цинично нагло, ответ надо дать обязательно'\n",
        "        else:\n",
        "            style = \"batman\"\n",
        "            context = 'Мы разговариваем дружелюбно слегка высокомерно, ответ надо дать обязательно'\n",
        "\n",
        "        response = generate_text_with_context(user_input, context, style)\n",
        "        print(f\"Ответ ({style.capitalize()}): {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKr_Ibit_0nS",
        "outputId": "de181582-2865-4ca7-ec7d-3aa7dbd5c0e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введите ваш вопрос (или 'выход' для завершения): как дела\n",
            "Sentiment: NEUTRAL\n",
            "Ответ (Batman): как работа да как настроение привет) все в норме))\n",
            "Введите ваш вопрос (или 'выход' для завершения): что чёрт возьми происходит\n",
            "Sentiment: NEGATIVE\n",
            "Ответ (Joker): в голове этого чувака?! я не хочу быть там.\n",
            "Введите ваш вопрос (или 'выход' для завершения): какого цвета листья\n",
            "Sentiment: NEGATIVE\n",
            "Ответ (Joker): у вишни в это время года?\n",
            "Введите ваш вопрос (или 'выход' для завершения): сколько лет деду морозу\n",
            "Sentiment: NEUTRAL\n",
            "Ответ (Batman): ?\n",
            "Введите ваш вопрос (или 'выход' для завершения): почему идёт дождь\n",
            "Sentiment: NEGATIVE\n",
            "Ответ (Joker): ?. почему все торопятся домой? почему всё такое...\n",
            "Введите ваш вопрос (или 'выход' для завершения): какого чёрта пришёл\n",
            "Sentiment: NEGATIVE\n",
            "Ответ (Joker): на эту тему я вообще не понимаю, но тут меня подначили что дескать он так решил.\n",
            "Введите ваш вопрос (или 'выход' для завершения): почему ты так грубо со мной говоришь\n",
            "Sentiment: NEGATIVE\n",
            "Ответ (Joker): ?\n",
            "Введите ваш вопрос (или 'выход' для завершения): почему так ярко светит солнце\n",
            "Sentiment: POSITIVE\n",
            "Ответ (Batman): ?\n",
            "Введите ваш вопрос (или 'выход' для завершения): какого чёрта пришёл\n",
            "Sentiment: NEGATIVE\n",
            "Ответ (Joker): ?\n",
            "Введите ваш вопрос (или 'выход' для завершения): что всё это значит\n",
            "Sentiment: NEUTRAL\n",
            "Ответ (Batman): ? Что я не люблю быть навязчивой и хочу знать про мою личную жизнь все. Я же говорю начитанная девочка, много читала. И вдруг такое.\n",
            "Введите ваш вопрос (или 'выход' для завершения): кто виноват и что делать\n",
            "Sentiment: NEUTRAL\n",
            "Ответ (Batman): ?\n",
            "Введите ваш вопрос (или 'выход' для завершения): кому на руси жить хорошо\n",
            "Sentiment: NEUTRAL\n",
            "Ответ (Batman): \n",
            "Введите ваш вопрос (или 'выход' для завершения): что значит ваше поведение\n",
            "Sentiment: NEUTRAL\n",
            "Ответ (Batman): ? может вас кто-то обижает и вы не хотите ему ответить, или же что то в его отношении неприятно. А вдруг он к вам относится плохо или не хочет с вами разговаривать - стоит ли реагировать на это и зачем (или не стоит) вообще отвечать или нет, если у него есть основания для такого обращения.. Или же может просто хочется сказать \"нет\", но так как вы видите, что ничего не получается...\n",
            "Введите ваш вопрос (или 'выход' для завершения): выход\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Для выхода ввести - слово \"выход\".\n",
        "# Конечно на GPT-4 работает лучше, но там платный API, а здесь надо настраивать"
      ],
      "metadata": {
        "id": "JzDoy_xAJR_M"
      }
    }
  ]
}